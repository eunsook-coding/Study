{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Recurrent Models of Visual Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 싸이그래머 의사결정 RL\n",
    "* 강은숙"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* (1) Overview\n",
    "    * (1.1) RNN\n",
    "\n",
    "\n",
    "* (2) Motivation\n",
    "\n",
    "\n",
    "* (3) Recurrent Attention Model (RAM)\n",
    "    * (3.1) Concept\n",
    "    * (3.2) Model Architecture\n",
    "    * (3.3) Model Training\n",
    "    \n",
    "    \n",
    "* (4) Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 논문은 Google DeepMind가 NIPS 2014에서 발표한 Recurrent Neural Network와 Reinforcement Learning을 결합한 논문 입니다. \n",
    "\n",
    "예전에 한번 살펴본 Playing Atari With Deep Reinforcement Learning 에서는 전통적인 RL 문제인 '게임'을 풀기 위하여 CNN으로 action-value function을 모델링하고 value iteration을 대체하는 새로운 action-value function learning 모델과 알고리즘을 제안했다면, \n",
    "\n",
    "이 논문은 기존 RL 문제라기보다는 오히려 좀 더 클래식한 classification 문제라고 할 수 있는 image recognition 문제에 RNN 구조와 RL구조를 결합하여 reward maximazation optimization problem을 푸는 모델과 알고리즘을 제안 합니다.\n",
    "\n",
    "## (1.1) RNN (Recurrent Neural Network) : 순환 신경망\n",
    "\n",
    "사람은 생각을 매 초 처음부터 하지 않습니다. 우리가 항상 어떤 글을 읽을 떄도 각 단어를 이전 단어에 기반을 두고 이해합니다. \n",
    "\n",
    "우리는 기존의 것을 모두 버리고 처음부터 생각을 하지 않습니다. 우리의 생각에는 지속성이 있습니다. \n",
    "\n",
    "순환 신경망은 이 주제를 다룹니다. 순환 신경망은 그 내부에 루프를 가진 네트워크로서 그 루프는 정보가 지속되는 것을 돕습니다. \n",
    "\n",
    "<img src = \"./image/rnn_1.png\">\n",
    "\n",
    "위 다이어그램에서 신경망 A는 입력값 xt를 보고 값 ht를 출력합니다. \n",
    "\n",
    "조금 더 살펴보면 루프들은 보통신경망과 다르지 않습니다. \n",
    "\n",
    "순환 신경망은 동일한 네트워크 여러개를 복사한 것으로도 생각할 수 있습니다. \n",
    "\n",
    "각 네트워크는 자신의 후임자에게 메시지를 전달하고, 그 루프가 펼쳐지면 아래와 같은 모양과 같습니다. \n",
    "\n",
    "<img src = \"./image/rnn_2.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Applying convolutional neural networks to large images is computationally expensive because the amount of computation scales linearly with the number of image pixels. \n",
    "\n",
    "\n",
    "* <font color=\"blue\">We present a novel recurrent neural network model that is capable\n",
    "of extracting information from an image or video by adaptively selecting\n",
    "a sequence of regions or locations and only processing the selected regions at\n",
    "high resolution.</font>\n",
    "\n",
    "\n",
    "\n",
    "* Like convolutional neural networks, the proposed model has a degree of translation invariance built-in, but the amount of computation it performs can be controlled independently of the input image size.\n",
    "\n",
    "\n",
    "* <font color=\"red\"> Our model considers attention-based processing of a visual scene as a control problem and is general enough to be applied to static images, videos, or as a perceptual module of an agent that interacts with a dynamic visual environment (e.g. robots, computer game playing agents).</font>\n",
    "\n",
    "이 논문에서는 CNN 기반으로 image Classification의 경우 이미 인간이 할 수 있는 수준에 거의 근접 하였지만, \n",
    "\n",
    "CNN을 사용할 경우 input Size가 fix되어 있어야 하고, pixel size가 엄청 크면 그 만큼 computation cost가 linearly 하게 증가 한다는 단점이 존재한다 라고 말하면서, \n",
    "\n",
    "논문에서 제안된 모델을 사용하게 되면, \n",
    "\n",
    "기존 CNN모델과 다르게 image의 크기가 바뀌더라도 computation이나 memory가 그 크기에 linear하게 증가하지 않고 모델에 의해 조절 가능하다는 특징을 말하고 있습니다. \n",
    "\n",
    "\n",
    "그래서 표현 된 모델은 전체적으로 이미지나 비디오를 보는 것이 아니라, RNN 모델을 사용하여 선택적으로 선별된 위치를 sequence로 나열하여 정보를 추출하겠다고 말하고 있습니다. \n",
    "\n",
    "\n",
    "여기 model에서 고려하고 있는 것은 실제 사람이 물체를 인식하거나 할 때를 생각해보면, 'attention'이 존재한다는 것을 알 수 있는데, \n",
    "즉, 배경을 포함한 모든 정보를 사용하여 물체를 인식하는 것이 아닌 자신이 focus하고 있는 일부분과 그 주변부의 정보들을 '훑어보면서' 훑어본 sequence들을 복합적으로 종합하여 결론을 내린다는 것을 알 수 있습니다. \n",
    "\n",
    "<font color=\"red\">그래서 'attention'을 고려한 human-like한 모델을 설계한 다면 기존 CNN의 단점을 해결하는 데에 도움이 될 수 있을 것이라는 것이 이 논문의 Motivation 입니다.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Recurrent Attention Model (RAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this paper we consider the attention problem as the sequential decision process of a goal-directed agent interacting with a visual environment. \n",
    "\n",
    "\n",
    "* At each point in time, the agent observes the environment only via a bandwidth-limited sensor, i.e. it never senses the environment in full.\n",
    "\n",
    "\n",
    "* The agent can, however, actively control how to deploy its sensor resources (e.g. choose the sensor location).\n",
    "\n",
    "이 논문에서는 attention problem을 visual 환경과 interact하는 목표지향적인 agent가 행하는 sequential decision process로 정의 합니다. \n",
    "\n",
    "각 time step마다 agent는 bandwidth-limited sensor(전체 environment를 보는것이 아닌)만을 사용해 environment를 observes 합니다. \n",
    "\n",
    "즉, agent는 한 번에 전체 environment를 감지하지 않고, 매 time step마다 local한 정보 만을 감지하고 \n",
    "\n",
    "sensor를 어떻게 사용할 지 다시 말해 sensor의 다음 location을 선택하는 action을 취할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3.1) Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 논문에서는 총 3개의 Network를 구성하여 문제를 풀고 있습니다. \n",
    "\n",
    "먼저 모델의 큰 그림을 보게되면 아래와 같은 RNN 형태의 neural network model을 제안 하고 있습니다. \n",
    "\n",
    "<img src = \"./image/model_1.png\">\n",
    "\n",
    "위에 제안된 모델에서 사용하는 변수들을 하나씩 살펴보면 아래와 같습니다. \n",
    "\n",
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mi>t</mi>\n",
    "  </msub> : agent가 time t에 관측한 environment (전체 image의 일부분)\n",
    "\n",
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <msub>\n",
    "    <mi>&#x2113;<!-- ℓ --></mi>\n",
    "    <mi>t</mi>\n",
    "  </msub>\n",
    "</math>: agent가 time t에 focus하고 있는 region의 좌표 값, 실제 agent는 ℓt의 주변을 관측한다. 이 값은 논문에서 sensor control의 action으로 사용된다.\n",
    "\n",
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <msub>\n",
    "    <mi>a</mi>\n",
    "    <mi>t</mi>\n",
    "  </msub>\n",
    "</math>: agent의 time t에서의 environment action. Classification의 경우는 atat가 classification을 하는 decision을 내리는 용도로 사용된다. 즉, MNIST data로 실험하는 경우 가능한 atat의 경우 수는 [0-9]이며, 각각 0부터 9까지의 숫자를 나타내게 된다.\n",
    "\n",
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <msub>\n",
    "    <mi>r</mi>\n",
    "    <mi>t</mi>\n",
    "  </msub>\n",
    "</math>: agent가 maximize하고자하는 목표 값이다. Image classification은 time t에서 정확한 classification을 했으면 reward가 1, 아니라면 reward가 0이 되도록 설정하였다고 한다.\n",
    "\n",
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <msub>\n",
    "    <mi>h</mi>\n",
    "    <mi>t</mi>\n",
    "  </msub>\n",
    "</math>: time t에서 agent의 state를 ‘hidden’ state로 표현한 것으로, 원래 state는 <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <msub>\n",
    "    <mi>s</mi>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mn>1</mn>\n",
    "      <mo>:</mo>\n",
    "      <mi>t</mi>\n",
    "    </mrow>\n",
    "  </msub>\n",
    "  <mo>=</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mn>1</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>&#x2113;<!-- ℓ --></mi>\n",
    "    <mn>1</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>a</mi>\n",
    "    <mn>1</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <mo>&#x2026;<!-- … --></mo>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mi>t</mi>\n",
    "      <mo>&#x2212;<!-- − --></mo>\n",
    "      <mn>1</mn>\n",
    "    </mrow>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>&#x2113;<!-- ℓ --></mi>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mi>t</mi>\n",
    "      <mo>&#x2212;<!-- − --></mo>\n",
    "      <mn>1</mn>\n",
    "    </mrow>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>a</mi>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mi>t</mi>\n",
    "      <mo>&#x2212;<!-- − --></mo>\n",
    "      <mn>1</mn>\n",
    "    </mrow>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mi>t</mi>\n",
    "  </msub>\n",
    "</math>로 표현되지만, 만약 ht를 이 모든 state들을 ‘summarize’하는 것과 같이 모델링 할 수 있다면, 전체 state를 보는 대신, summerized internal state인 ht로 state 표현을 대신할 수 있다.\n",
    "\n",
    "### <font color=\"blue\">여기서 각 네트워크에 대해서 살펴보면 아래와 같습니다.</font>\n",
    "* f(g) : imput data에 대한 정보를 처리하는 네트워크 (glimpse network)\n",
    "\n",
    "\n",
    "* f(l) : sensor의 위치 정보를 결정하는 네트워크 (location network)\n",
    "\n",
    "\n",
    "* f(a) : action의 값을 결정하는 네트워크 (action network) \n",
    "    * 여기에서 action에 해당 하는 것은 image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3.2) Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저, f(g)에 대한 Glimpse Network에 대해서 살펴보면, 이 네트워크는 아래 그림과 같이 Glimpse Sensor, Glimpse Network 두개로 나눠 생각해 볼 수 있습니다. \n",
    "\n",
    "<img src = \"./image/model_2.png\">\n",
    "\n",
    "* A) Glimpse Sensor\n",
    "    - 주어진 이미지  xt의 한 위치 l t-1을 받아서 해당 위치에서 특정 거리 d1만큼 떨어진 이미지를 추출합니다. \n",
    "    - 그리고 그것보다 더 넓은 범위인 d2, d3... 만큼 떨어진 이미지를 추출하는 과정을 k번 반복하여 k개의 patch를 만들어 냅니다. \n",
    "    - 이렇게 하는 이유는 사람의 망막이 중심부에 가까울 수록 데이터의 해상도를 높게 받아들이고 중심부에서 멀어질수록 이미지가 흐려지도록 처리하기 때문입니다. \n",
    "    - Sensor에서 이 값들을 생성하고 나면 <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>&#x03C1;<!-- ρ --></mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mi>t</mi>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>&#x2113;<!-- ℓ --></mi>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mi>t</mi>\n",
    "      <mo>&#x2212;<!-- − --></mo>\n",
    "      <mn>1</mn>\n",
    "    </mrow>\n",
    "  </msub>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "</math> 이라는 transform의 결과가 만들어지게 됩니다. \n",
    "\n",
    "\n",
    "* B) Glimpse Network\n",
    "    - Glimpse Sensor를 통해 나온 결과 값을 통해 그 정보를 잘 정리하여 주어진 RNN Core Network가 정보를 잘 처리할 수 있도록 만들어주는 역할을 합니다. \n",
    "    - 모든 glimpse network의 lyaer들은 기본적인 inner product layer를 사용합니다 <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>L</mi>\n",
    "  <mi>i</mi>\n",
    "  <mi>n</mi>\n",
    "  <mi>e</mi>\n",
    "  <mi>a</mi>\n",
    "  <mi>r</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <mi>x</mi>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "  <mo>=</mo>\n",
    "  <mi>W</mi>\n",
    "  <mi>x</mi>\n",
    "  <mo>+</mo>\n",
    "  <mi>b</mi>\n",
    "</math>. \n",
    "\n",
    "    - 그리고 neuron으로는 ReLU unit <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>R</mi>\n",
    "  <mi>e</mi>\n",
    "  <mi>L</mi>\n",
    "  <mi>U</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <mi>x</mi>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "  <mo>=</mo>\n",
    "  <mo movablelimits=\"true\" form=\"prefix\">max</mo>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <mi>x</mi>\n",
    "  <mo>,</mo>\n",
    "  <mn>0</mn>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "</math> ReLU(x)=max(x,0))을 사용합니다. \n",
    "\n",
    "    - 즉, <math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
    "  <msub>\n",
    "    <mi>h</mi>\n",
    "    <mi>g</mi>\n",
    "  </msub>\n",
    "  <mo>=</mo>\n",
    "  <mi>R</mi>\n",
    "  <mi>e</mi>\n",
    "  <mi>L</mi>\n",
    "  <mi>U</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <mi>L</mi>\n",
    "  <mi>i</mi>\n",
    "  <mi>n</mi>\n",
    "  <mi>e</mi>\n",
    "  <mi>a</mi>\n",
    "  <mi>r</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <mi>&#x03C1;<!-- ρ --></mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <mi>x</mi>\n",
    "  <mo>,</mo>\n",
    "  <mi>&#x2113;<!-- ℓ --></mi>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>h</mi>\n",
    "    <mi>&#x2113;<!-- ℓ --></mi>\n",
    "  </msub>\n",
    "  <mo>=</mo>\n",
    "  <mi>R</mi>\n",
    "  <mi>e</mi>\n",
    "  <mi>L</mi>\n",
    "  <mi>U</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <mi>L</mi>\n",
    "  <mi>i</mi>\n",
    "  <mi>n</mi>\n",
    "  <mi>e</mi>\n",
    "  <mi>a</mi>\n",
    "  <mi>r</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <mi>&#x2113;<!-- ℓ --></mi>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "</math>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "전체적인 Model의 구성도를 살펴보면 아래 그림과 같이 표현됩니다. \n",
    "<img src = \"./image/model_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3.2) Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이 네트워크에서 우리가 learning해야할 parameter는 glimpse network, core network 그리고 action network의 parameter인 θg,θh,θa 입니다. \n",
    "\n",
    "\n",
    "* Optimization을 하기 위한 target function은 total reward를 maximize하는 함수로 설정할 것이고, \n",
    "\n",
    "* We follow this approach for classification problems where we optimize the cross entropy loss to train the action network fa and backpropagate the gradients through the core and glimpse networks.\n",
    "\n",
    "* The location network fl is always trained with REINFORCE.\n",
    "\n",
    "* loss는 cross entropy loss를 사용하고, fl 네트워크는 RL을 사용하여 학습시킵니다. \n",
    "\n",
    "* 그래서 여기서는 target function의 p(s1:T;θ)에 대한 expectation을 maximize하는 문제로 reward maximization problem을 formal하게 정의할 수 있습니다.\n",
    "\n",
    "<img src = \"./image/equation_1.png\">\n",
    "\n",
    "\n",
    "* 그러나 이 함수 J(θ)를 maximize하는 것은 trivial(사소한)한 일이 아닌데, 다행스럽게도 이미 예전에 다른 work에서 이 J(θ)의 gradient의 sample approximation이 아래와 같이 유도된다는 것을 보였다고 합니다. \n",
    "\n",
    "\n",
    "<img src = \"./image/equation_2.png\">\n",
    "\n",
    "* 위의 관계식에서의 ∇θlogϕ(uit | si1:t;θ)은 RNN의 gradient를 계산해야하는 것으로 간단하게 구할 수 있다. 다만 이 관계식이 unbiased estimation of gradient를 제공하기는 하지만, variance가 너무 높다는 단점이 있다고 한다. 그래서 이 논문에서는 아래와 같은 form으로 gradient를 estimation하여 variance의 값을 줄이도록 하였다고 합니다. \n",
    "\n",
    "<img src = \"./image/equation_3.png\">\n",
    "\n",
    "\n",
    "<img src = \"http://sanghyukchun.github.io/images/post/91-6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 기존 CNN 기반 접근 방식의 문제점들 - 이미지 사이즈에 linear한 computation cost, human-like 하지 않은 처리 방법 등 - 을 처리하기 위한 목적으로 디자인되었음\n",
    "\n",
    "\n",
    "* 사람이 정보를 한 번에 처리하는 것이 아니라 배경을 무시하고 이미지의 일부만 인식하듯, ‘attention’을 모델에 대입하는 아이디어를 제안함\n",
    "\n",
    "\n",
    "* Attention을 neural network에 도입하기 위하여 RNN과 Reinforcement Learning을 결합한 형태의 모델을 사용함\n",
    "\n",
    "\n",
    "* RNN의 input으로는 이미지 정보, 위치 정보가 있으며, 그것들을 조금 더 retina-like하게 처리하기 위한 glimpse network라는 것을 추가로 붙여서 input으로 사용함\n",
    "\n",
    "\n",
    "* output으로는 action network, location network가 있는데, action network는 classification을 위한 linear classifier이고, location network는 다음 state에 영향을 미치는 recurrent하게 다음 input과 함께 glimpse network의 input으로 쓰이는 값임\n",
    "\n",
    "\n",
    "* reward는 time t에 올바른 classification을 하였는지 아닌지를 판단하여 0-1 으로 reward를 return함\n",
    "\n",
    "\n",
    "* train을 하기 위하여 reward maximization을 하는데, 직접 gradient를 구하는 것이 non-trivial하여 estimation값을 사용함. 이때 unbaised estimator는 variance가 높아서 low variance estimator를 사용하여 update를 함\n",
    "\n",
    "\n",
    "* MNIST에 대해 실험을 하였으며, centered digit은 기존 state-of-art에 비해 턱없이 모자라지만, 사람은 구분할 수 있지만 머신은 제대로 판단하지 못하는 cluttered non-centered digit을 기존 fully connected network보다 훨씬 잘 판별하는 것을 알 수 있었음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료\n",
    "* [1] Recurrent Model of Attention : https://papers.nips.cc/paper/5542-recurrent-models-of-visual-attention.pdf\n",
    "* [2] http://sanghyukchun.github.io/91/\n",
    "* [3] RNN : http://www.whydsp.org/280"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
