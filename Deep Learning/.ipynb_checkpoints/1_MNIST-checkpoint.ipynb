{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic MNIST \n",
    "\n",
    "- dataset download\n",
    "http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./samples/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./samples/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./samples/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./samples/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./samples/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다운로드한 데이터는 \n",
    "1. 55000개의 학습 데이터 - mnist.train\n",
    "2. 10000개의 테스트 데이터 - mnist.text\n",
    "3. 5000개의 검증 데이터 - mnist.validation\n",
    "\n",
    "이렇게 나눠진 것은 굉장히 중요!\n",
    "\n",
    "학습하지 않은 별도의 데이터를 이용해서 학습한 결과가 실제로 일반적으로 적용되는지 검증하는 것이 \n",
    "### 기계 학습의 핵심!\n",
    "\n",
    "모든 MNIS 데이터 포인트 들은 두 부분으로 되어 있음. \n",
    "1. 손으로 쓴 숫자 이미지 - \"xs\"\n",
    "2. 그에 해당하는 라벨 - \"ys\"\n",
    "\n",
    "예를들어)\n",
    "- 학습 세트의 이미지는 mnist.train.images\n",
    "- 학습 세트의 라벨은 mnist.train.labels\n",
    "\n",
    "각 이미지는 가로, 세로 각 28픽셀.\n",
    "이걸 숫자로 구성된 큰 행렬로 취급 가능\n",
    "\n",
    "<img src=\"https://resources.codeonweb.com/bucket/cached/d4/e5/d4e5709ebb4ba940126de44c76ca71b0.png\" />\n",
    "\n",
    "우리는 이 행렬을 28X28 = 784개의 숫자를 갖는 벡터로 단순화할 수 있음.\n",
    "우리가 이미지들에 모두 동일한 방법을 적용하는 한, 어떻게 행렬을 단순화하는지는 중요하지 않음.\n",
    "이 관점에서 보면 MNIST 이미지들은 그저 784차원 벡터 공간 안에서 아주 풍부한 구조를 지닌 점들일 뿐임.\n",
    "(주의 : 컴퓨터 자원이 많이 필요한 시각화임.)\n",
    "\n",
    "<font color=\"blue\">\n",
    "데이터를 단순화하는 과정은 이미지의 2차원 구조를 버린다.\n",
    "이게 안좋을까? \n",
    "글쎼... 최고의 컴퓨터 비전 방법들은 이 구조도 전부 이용하고 있고, \n",
    "우리도 이후의 예제에서 그렇게 할 것임.\n",
    "그러나, 우리가 여기서 이용할 간단한 방법인 소프트맥스 회귀에서는 2차원 구조를 사용하지 않음. \n",
    "</font>\n",
    "\n",
    "결과로 mnist.train.images 는 [55000, 784] 형태의 텐서(n차원 행렬)을 얻었음.\n",
    "\n",
    "첫 번째 차원 인덱스는 이미지에, \n",
    "두 번째 차원 인덱스는 각 이미지의 픽셀에 대응됨.\n",
    "\n",
    "텐서의 각 구성 요소들은 특정 이미지 안의 특정한 픽셀의 진하기를 0~1 사이의 값으로 나타냄.\n",
    "\n",
    "<img src=\"https://resources.codeonweb.com/bucket/cached/01/44/01442103dfbc7159abd9382d832fb07e.png\" />\n",
    "\n",
    "\n",
    "MNIST 안에서 대응되는 라벨들은 주어진 각 이미지가 어떤 숫자를 나타내는가를 의미하는 0~9 사이의 숫자.\n",
    "\n",
    "이 연습의 목적으로, 우리는 우리 라벨들을 \"one-hot vector\"로 사용할 것.\n",
    "\n",
    "이 경우 n번째 숫자는 n번째 차원이 1인 벡터로 표시됨.\n",
    "\n",
    "예를 들어) 3은 [0,0,0,1,0,0,0,0,0,0]로 표시.\n",
    "따라서, mnist.train.labels.sms [55000, 10] 행렬이 됨.\n",
    "\n",
    "<img src=\"https://resources.codeonweb.com/bucket/cached/29/32/2932868078c91f45f92b2eefa005ff4a.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression\n",
    "\n",
    "우리는 MNIST의 모든 이미지가 0~9까지의 숫자인 것을 알고 있다.\n",
    "우리의 목표는 학습 모델이 이미지를 보았을 때 각 숫자로 판단할 확률을 얻고자 하는 것이다.\n",
    "\n",
    "이 경우는 소프트맥스 회귀가 자연스럽고 간단한 모델인 고전적인 경우이다. \n",
    "만약 어떤 대상이 여러 다양한 것들 중 하나일 확률을 계산하려면 소프트맥스가 가장 적당하다. \n",
    "심지어 나중에 우리가 훨씬 더 정교한 모델들을 배웠을 떄에도 마지막 단계는 소프트맥스 레이어일 것이다.\n",
    "\n",
    "### 소프트맥스 회귀의 두 단계\n",
    "1. 우리 입력이 특정 클래스에 해당되는지에 대한 증거를 더하고\n",
    "2. 그 다음 증거를 확률로 변환.\n",
    "\n",
    "주어진 이미지가 특정한 클래스에 들어가는지의 증거를 모아 계산하기 위해 픽셀 농도의 가중합을 사용.\n",
    "특정 클래스 안의 이미지들의 픽셀들에 비해 \n",
    "픽셀 농도가 높을 경우 가주치는 음수이고, \n",
    "그렇지 않을 경우 가중치는 양수.\n",
    "\n",
    "아래의 다이어그램은 세가지 클래스 각각에 대해 학습한 모델의 가중치를 보여준다. \n",
    "\n",
    "빨간색은 음수 가중치 / 파란색은 양수 가중치\n",
    "\n",
    "<img src=\"https://resources.codeonweb.com/bucket/cached/9b/79/9b792345c0394ce51d9b08b66287f5fd.png\" />\n",
    "\n",
    "이제 편향(bias)이라고 불르는 추가적인 증거를 더함.\n",
    "기본적으로, 우리는 몇몇 경우들은 입력들에 대해 더 자유롭다고 말할수 있게 하고 싶다. \n",
    "결과적으로 주어진 입력 x에 대한 클래스 i의 증거는\n",
    "\n",
    "<img src=\"images/evidence.png\" />\n",
    "\n",
    "Wi는 가중치, bi는 클래스 i에 대한 편향, j는 입력한 이미지 x의 픽셀들에 따른 합을 구하기 위한 인덱스.\n",
    "이제 증거 항목들을 \"softmax\"함수를 이용해 예측 확률로 변환함.\n",
    "\n",
    "<img src=\"images/softmax.png\" />\n",
    "\n",
    "여기서 소프트맥스가 우리가 제공한 선형 함수의 출력 결과를 원하는 형태로 만들기 위해\n",
    "\"활성화\"나 \"링크\" 함수의 형태로 적용됨.\n",
    "\n",
    "이 경우, 10가지 경우에 대한 확률 분포이다. \n",
    "이것의 증거 항목들을 각 클래스에 대응하는 확률로 변환하는 과정으로 생각해도 됨. \n",
    "이 과정은 다음과 같이 정의됨.\n",
    "\n",
    "<img src=\"images/normalize.png\" />\n",
    "\n",
    "이 식을 전개하면 다음과 같은 결과를 얻음. \n",
    "\n",
    "<img src=\"images/normalize_open.png\" />\n",
    "\n",
    "그러나, 종종 소프트맥스의 입력을 지수화하고 정규화하는 첫 번째 방법으로 생각하는 것이 훨씬 도움이 된다. \n",
    "지수화는 증거에 하나가 더해질 경우 가중치를 곱으로 증가시키는 의미가 된다. \n",
    "\n",
    "반대로 말하면, 증거에서 하나가 줄어들면 가설의 가중치가 원래 가중치의 분수비로 줄어든다는 의미가 된다. \n",
    "어떤 가설도 0이나 음수의 가중치를 가질 수 없다. \n",
    "\n",
    "그런 후 소프트맥스는 이러한 가중치를 정규화해서, 모두 더하면 1이 되는 확률 분포의 형태로 만든다. \n",
    "(소프트맥스 함수에 대한 더 많은 직관을 얻고 싶다면, 시각화가 있는 마이클 닐센의 책의 챕터를 참고 바람.)\n",
    "\n",
    "소프트맥스 회귀를 아래와 같이 그려볼 수 있음. \n",
    "(훨씬 많은 x가 있다는 것만 제외하면) 각각의 출력마다, \n",
    "우리는 가중치의 합을 계산하고, 편향을 더하고, 소프트 맥스를 적용한다.\n",
    "\n",
    "<img src=\"https://resources.codeonweb.com/bucket/cached/3d/eb/3debe13595e70edb78dfe62fe562688a.png\" />\n",
    "\n",
    "식 형태로 쓰면 :\n",
    "\n",
    "<img src=\"https://resources.codeonweb.com/bucket/cached/c4/fe/c4febfa77b4a0c19e81e41eb6d989800.png\" />\n",
    "\n",
    "우리는 이 과정을 행렬곱과 벡터 합으로 바꾸는 식으로 \"벡터화\" 할 수 있다. \n",
    "벡터화는 계산 효율을 위해서 도움이 된다. \n",
    "\n",
    "<img src=\"https://resources.codeonweb.com/bucket/cached/fa/99/fa991ee0070b1abad576b2edc0aaa54f.png\" />\n",
    "\n",
    "더 간단하게는 그냥 이렇게 쓸 수 있음.\n",
    "\n",
    "<img src=\"images/softmax_final.png\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x틑 특별한 값이 아니라 수식기호.\n",
    "\n",
    "우리는 MNIST 이미지들의 어떤 숫자들이든 입력할 수 있기를 원하는데, 각 이미지들은 784차원의 벡터로 단조화 되어 있음. \n",
    "\n",
    "우리는 이걸 [None, 784] 형태의 부동소수점으로 이루어진 2차원 텐서로 표현함. \n",
    "(None은 해당 값이 어떤 길이도 될 수 있음을 의미)\n",
    "\n",
    "우리는 가중치와 편향이 필요!\n",
    "TensorFlow의 variable변수를 사용\n",
    "이 것은 상호작용하는 작업 그래프들간에 유지되는 변경 가능한 텐서 / 꼐산 과정에서 사용되거나 변경될 수도 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 학습시키기 위해서, 우선 모델에게 무엇이 좋은지를 정의하는 것이 필요함. \n",
    "기계학습에서는 일반적으로 모델에게 있어서 무엇이 나쁜지 정의하고 (비용(cost) / 손실(loss)) 나쁜정도를 최소화 하려고 시도. (두가지는 동일하다)\n",
    "\n",
    "아주 일반적이고 굉장히 괜찮은 비용 함수는 \"교차 엔트로피(cross-entropy)\"이다. \n",
    "놀랍게도 교차 엔트로피는 정보 이론에서 정보 압축 코드에 대한 생각에서 출발했으나,\n",
    "도박부터 기계학습까지 아주 다양한 분야들에서 중요한 아이디어가 됐음.\n",
    "\n",
    "아래와 같이 정의됨 \n",
    "\n",
    "<img src=\"images/cross-entropy.png\" />\n",
    "\n",
    "y는 우리가 예측한 확률 분포, y'는 실제 분포 (우리가 입력할 one-hot벡터)\n",
    "대략적인 관점에서 보면, 교차 엔트로피는 우리 예측이 참값을 표현하는데 얼마나 비효율적인지를 측정함. \n",
    "\n",
    "교차 엔트로피 구현을 위해 우선적으로 정답을 입력하기 위한 새 placeholder를 추가 해야함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번쨰로, tf.log는 y의 원소의 로그값을 계산.\n",
    "\n",
    "그 다음 y_의 각 원소들에 대해 tf.log(y) 를 곱함. \n",
    "\n",
    "마지막으로, tf.reduce_sum은 텐서의 모든 원소를 더함.\n",
    "- 미니배치 안의 모든 이미지들에 걸쳐 합을 구할 뿐 아니라, 클래스에 대해 수행됨. \n",
    "- 여기서는 교차 엔트로피를 전체 미니배치에 대해 계산하고 있음. \n",
    "\n",
    "알아둘 것은 이 값이 단지 한 번의 예측에 대한 참값의 교차 엔트로피값이 아니라, \n",
    "\n",
    "우리가 본 모든 이미지들에 대한 교차 엔트로피의 합이라는 점이다. \n",
    "\n",
    "이 예제에서는 각 배치마다 100개의 이미지들이 있다. \n",
    ": 우리가 100개의 데이터 포인트들에 대해 얼마나 잘 동작하는지 보는 것은 하나의 데이터 포인트에 대한 것보다\n",
    "훨씬 좋은 기술 방법임.\n",
    "\n",
    "우리 모델이 무엇을 해야 하는 것을 안다면, TensorFlow에게 가르치는 것은 정말 쉽다. \n",
    "\n",
    "TensorFlow는 당신 계산 과정의 전체 그래프를 알고 있기 때문에, \n",
    "자동적으로 역전파(backpropagation) 알고리즘을 이요하여 비용 최소화에 어떤 변수가 얼마나 영향을 주는지를 효율적으로 계산 한다. \n",
    "\n",
    "그리고 우리가 선택한 최적화 알고리즘을 적용하여 변수들을 수정하고 비용을 최소화 할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000) :\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x : batch_xs, y_ : batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 반복 단계마다, 학습 세트로부터 100개의 무작위 데이터들의 일괄 처리(batch)들을 가져온다. \n",
    "placeholders 를 대체하기 위한 일괄 처리 데이터에 train_step피딩을 실행한다. \n",
    "\n",
    "무작위 데이터의 작은 일괄처리를 이용하는 방법을 확률적 교육(Stochastic training)라고 한다. \n",
    "이 경우에는 확률적 경사 하강법 이디ㅏ. \n",
    "이상적으로 무엇을 해야 할지에 대해 더 나은 직관을 줄 수 있도록 학습의 모든 단계에 모든 데이터를 사용하고 싶지만\n",
    "그 과정은 계산의 비용이 많이 든다. \n",
    "\n",
    "그래서, 그 대신에 우리는 각 시간마다 다른 서브셋을 사용하는데 \n",
    "이렇게 하면 계산 비용이 적게 들어가면서 비슷한 효과를 볼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선, 맞는 라벨을 예측했는지를 확인해보자.\n",
    "tf.argmax는 특정한 축을 따라 가장 큰 원소의 색인을 알려주는 엄청나게 유용한 함수이다. \n",
    "예를 들어, tf.argmax(y, 1)는 진짜 라벨이 tf.argmax(y_, 1)일때 우리 모델이 각 입력에 대해 가장 정확하다고 생각하는 라벨이다. \n",
    "\n",
    "우리는 tf.equal을 이용해 예측이 실제와 맞았는지 확인 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9149\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={x : mnist.test.images, y_ : mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist.images와 mnist.labels의 실제 값들을 직접 보고싶다면 아래와 같이 작성한 후 확인한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_a = [4 0 0 8 3 2 9 1 0 8 7 4 4 7 9 6 9 0 9 8 0 9 6 0 6 5 5 9 8 3 3 9 3 3 2 7 8\n",
      " 0 1 8 1 7 0 6 5 4 3 3 0 9 6 3 8 0 9 9 6 8 6 8 5 9 8 6 0 2 9 0 2 8 3 1 9 7\n",
      " 5 8 0 8 4 6 8 6 7 9 9 6 9 8 2 2 9 2 7 3 5 9 1 8 0 2]\n",
      "diff_b = [4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8\n",
      " 0 8 2 1 7 0 6 5 4 3 8 0 9 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7\n",
      " 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1) :\n",
    "    batch_x, bathc_y = mnist.test.next_batch(100)\n",
    "    diff_a = sess.run(tf.argmax(y, 1), feed_dict={x : batch_x})\n",
    "    diff_b = sess.run(tf.argmax(y_, 1), feed_dict={y_ : bathc_y})\n",
    "    \n",
    "    print \"diff_a = \" + str(diff_a)\n",
    "    print \"diff_b = \" + str(diff_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Output a : [7 9 0 2 0 3 3 7 4 9]\n",
      "Sample Output b : [7 9 0 2 0 3 3 7 6 9]\n",
      "compare: ['T']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-cd7a1f4eb4cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoordi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12114ef50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2) :\n",
    "    result_boolean = []\n",
    "    batch_x, batch_y = mnist.test.next_batch(10)\n",
    "    diff_a = sess.run(tf.argmax(y, 1), feed_dict={x : batch_x})\n",
    "    diff_b = sess.run(tf.argmax(y_, 1), feed_dict={y_ : batch_y})\n",
    "    print \"Sample Output a : \" + str(diff_a)\n",
    "    print \"Sample Output b : \" + str(diff_b)\n",
    "    \n",
    "    for k in range(9):\n",
    "        if diff_a[k] == diff_b[k] :\n",
    "            result_boolean.append(\"T\")\n",
    "        else :\n",
    "            result_boolean.append(\"F\")\n",
    "        print \"compare: \" + str(result_boolean)\n",
    "\n",
    "        plt.figure(i)\n",
    "        coordi = [191, 192, 193, 194, 195, 196, 197, 198, 199]\n",
    "\n",
    "        for index, image in enumerate(batch_x) :\n",
    "            image.shape(28, 28)\n",
    "            plt.subplot(coordi[index])\n",
    "            plt.imshow(image)\n",
    "\n",
    "        print \"sample input : \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample output : [3 4 9 6 6 5 4 0 7]\n",
      "compare : ['T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-2b85fe04c5d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoordi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e823f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    result_boolean = []\n",
    "    batch_x, batch_y = mnist.test.next_batch(9)\n",
    "    diff_a = sess.run(tf.argmax(y,1), feed_dict={x:batch_x})\n",
    "    diff_b = sess.run(tf.argmax(y_,1), feed_dict={y_:batch_y})\n",
    "    print \"sample output : \" + str(diff_a)\n",
    "\n",
    "    for k in range(9):\n",
    "        if diff_a[k] == diff_b[k]:\n",
    "            result_boolean.append(\"T\")\n",
    "        else:\n",
    "            result_boolean.append(\"F\")\n",
    "    print \"compare : \" + str(result_boolean)\n",
    "\n",
    "    plt.figure(i)\n",
    "    coordi = [191, 192, 193, 194, 195, 196, 197, 198, 199]\n",
    "\n",
    "    for index, image in enumerate(batch_x):\n",
    "        image.shape(28,28)\n",
    "        plt.subplot(coordi[index])\n",
    "        plt.imshow(image)\n",
    "print \"sample input : \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
